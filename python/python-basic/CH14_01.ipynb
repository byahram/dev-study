{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f4b2a409-2ef3-4af8-9f23-42f03e6c4a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "[BeautifulSoup]\n",
    "\n",
    "- HTML 및 xml 문서를 파싱(분석)하고, 원하는 데이터를 손쉽게 추출할 수 있게 도와주는 파이썬 라이브러리이다.\n",
    "- 웹 페이지에서 특정 태그, 클래스, ID 등을 기준으로 데이터를 검색하고 추출하는데 유용하며, 웹 크롤링과 웹 스크래핑을 할 때 자주 사용된다.\n",
    "'''\n",
    "\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f37bf55a-f344-4ce4-989f-ba900c39e7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 경로\n",
    "file_path = \"C:/Users/user/Downloads/웹크롤링.html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6be1dacb-b5d0-42cd-bead-bcd68063588c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "[HTML 파일 열기]\n",
    "\n",
    "- with open(...) as f : 파일을 열겠다.\n",
    "    -> r : 읽기 모드\n",
    "    -> w : 쓰기 전용(기존 파일은 지워짐)\n",
    "    -> a : 이어쓰기(append)\n",
    "\n",
    "[f.read()]\n",
    "\n",
    "- 파일 전체 내용을 한 번에 문장열로 읽어오는 것. 이 결과는 html 변수에 저장된다.\n",
    "'''\n",
    "\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f :\n",
    "    html = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e00458fc-a689-4628-8a36-4bfdb26b4628",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "[BeautifulSoup으로 파싱하는 법]\n",
    "\n",
    "1. html.parser : 문서를 구조적으로 해석하는 프로그램이다.\n",
    "2. lxml - 빠르다.\n",
    "3. html5lib - html5 기준으로 정밀하게 해석\n",
    "'''\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ec6ef7ad-a03a-4d36-9598-438d0b5ed42e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "제목 :  보이는 제목 \n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "[예제 1] 제목(h1) 태그 찾기\n",
    "'''\n",
    "\n",
    "title_tag = soup.find(\"h1\")\n",
    "print(\"제목 :\", title_tag.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b90a4af0-9b17-480f-a040-dcf21c01f6a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "할 일: 아침 먹기\n",
      "할 일: HTML 배우기\n",
      "할 일: 복습하기\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "[예제 2] 목록(li) 전부 출력\n",
    "'''\n",
    "\n",
    "list_items = soup.find_all(\"li\")\n",
    "for item in list_items :\n",
    "    print(\"할 일:\", item.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4ece9e25-d3fd-4d79-ac79-59305993c42b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 주소: https://search.pstatic.net/common/?src=http%3A%2F%2Fblogfiles.naver.net%2FMjAyNTAzMjlfMSAg%2FMDAxNzQzMjI1NjE0OTk2.kZ_6xaECjWK245yJIBTZB_gCGMAzN89e_p81l124gwMg.7uXEYKUSsDD2VDgeG6A5nAyWAg9QjNvzxKjaAa70iNUg.PNG%2F2a53f73b-eba8-4e58-9f82-86b34ebbae8f.png&type=sc960_832\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "[예제 3] 이미지 주소 출력\n",
    "'''\n",
    "\n",
    "img_tag = soup.find(\"img\")\n",
    "print(\"이미지 주소:\", img_tag[\"src\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
